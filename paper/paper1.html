<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>SophiaAlignment</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">S<sup>2</sup>PRM: Providing Crucial Reward for LLM
                            Reasoning</h1>
                        <h1 class="title is-1 publication-title">by Soft-step Process Reward Model</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yuliang Liu
                                </a>
                                <sup>*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Junjie Lu</a><sup>*</sup>,
                            </span>
                            <span class="author-block">
                                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Zhaoling Chen</a>,
                            </span>
                            <span class="author-block">
                                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Chaofeng Qu</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Zefan Cai<sup></sup>
                                , JK Liu, Chonghan Liu,</span>

                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Zefan Cai<sup></sup>
                                Yunhui Xia<sup></sup>
                                ,
                                Chuheng Zhang<sup>#</sup>, Wei Shen<sup>#</sup>, Jiang Bian<sup></sup>
                                , Zhouhan Lin<sup>#</sup></span>

                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Zefan Cai<sup></sup>
                                *Indicates Equal Contribution
                                #Indicates Equal Contribution</span>

                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Arxiv PDF link -->
                                <span class="link-block">
                                    <a href="/" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <img class="myiconimg" src="static/images/home.svg" alt="">
                                        </span>
                                        <span>Home</span>
                                    </a>
                                </span>

                                <!-- Supplementary PDF link -->
                                <span class="link-block">
                                    <a herf="#" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <img class="myiconimg" src="static/images/paper.svg" alt="">
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                                    <a href="/release" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <img class="myiconimg" src="static/images/release.svg" alt="">
                                        </span>
                                        <span>Release</span>
                                    </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                                    <a href="/about" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <img class="myiconimg" src="static/images/about.svg" alt="">
                                        </span>
                                        <span>About</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>



    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 style="text-align: center;font-size: 2rem;font-weight:600">Abstract</h2>
                    <div class="content has-text-justified">
                        <div class="text">
                            Process Reward Models (PRMs) have emerged as
                            an effective method to enhance the multi-step reasoning abilities of large language models
                            (LLMs).
                            Existing PRMs typically divide the response into
                            multiple reasoning steps using pre-defined placeholder tokens. However, this approach
                            ignores
                            that the true decision points are usually not associated with specific words or markers in
                            text.
                            Accordingly, we propose a model-defined reasoning step dividing method, which contrasts with
                            human-defined hard division strategies, with the
                            trained PRM named S<sup>2</sup>PRM (Soft-step Process
                            Reward Model) This approach not only enables
                            precise process rewards at model-critical reasoning positions but also improves sample
                            efficiency
                            and reduces PRMsâ€™ training costs. Furthermore,
                            this method is low-cost and can easily be extended
                            to other reasoning tasks, such as code generation.
                            Our experimental results demonstrate that our
                            model achieves state-of-the-art Best-of-N performance. Additionally, we provide a
                            comprehensive
                            analysis and case study on both the performance
                            and generalization capability of our method. For
                            ease of reimplementation, our checkpoints, data and code
                            are available at
                            <a class="link" href="https://sophiaalignment.github.io/release/">Release</a>.
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->


    <section class="section hero ">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method Overview</h2>
                    <div class="content has-text-justified">
                        <img alt="" src="static/images/figure-method-main_00.png" class="myimages">
                        <div class="text">
                            Method overview.a) <strong>S<sup>2</sup>PRM Training Data Construction Pipeline.</strong> â‘ :
                            Sampling from the
                            dataset of a
                            certain domain and getting confidence and samples for the training dataset; â‘¡: Gathering the
                            confidence distribution
                            of all samples and getting threshold that divides the distribution into steps of 2% of the
                            token numbers; â‘¢:
                            Dividing
                            reasoning steps by threshold and labeling steps by rollout. <strong>b) the difference
                                between hard and soft step
                                division.</strong>
                            <font color="blue">Hard-step</font> corresponds to dividing the reasoning process by
                            pre-defined symbols (e.g., the
                            line break in the figure),
                            while <font color="red">soft-steps</font> are determined by inference model judgment. We
                            find that the model is
                            likely to perform soft step
                            segmentation within mathematical expressions, select variables or pronouns, and determine
                            the final answer. We
                            annotated the confidence score during model inference at division positions, where lower
                            confidence indicates that
                            the model finds it hard to decide.
                        </div>
                        <img alt="" src="static/images/figure-method-PGI_00.png" class="myimages">
                        <div class="text">
                            Method overview.b) We illustrate PGI by a simple example, the green token denotes the
                            selected tokens, whereas the
                            gray
                            token indicate the tokens that were not selected. The question is 3 * ( 1 + 1 ) = ?, and the
                            output should be 6; in
                            this case, the task model exhibits low confidence (where Cy < Ï„ ) when calculating the
                                answer of 1 + 1, and then determine which number to plus with 3, PRM should select the
                                best token it judges to get the correct final answer. </div>
                        </div>
                    </div>
                </div>
            </div>
    </section>

    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method</h2>
                    <div class="papercontent">
                        <div class="text">
                            In this section, we first introduce the preliminaries of the language model inference
                            process, then
                            illustrate
                            our method
                            that divides the reasoning process and estimates the reward.
                            Finally, we illustrate the proposed PRM-guided inference.
                        </div>
                        <div class="title-little">
                            1. Preliminaries
                        </div>
                        <div class="text">
                            Let $\phi$ denote the neural network function that maps the
                            input sequence X and previously generated tokens $y_{&lt;i}$ =
                            ($y_1$, $y_2$, . . . , $y_i$âˆ’1) to the logits vector $l_i$ for predicting the
                            next token $y_i$
                            , $l_i$ âˆˆ R<sup>|V|</sup> where |V| is the vocabulary size:
                        </div>
                        <div class="text">
                            \begin{equation}
                            \mathbf{l}_i=\phi\left(X, y_{&lt;i}\right) \nonumber
                            \end{equation}

                        </div>
                        <div class="text">
                            Each element of $l_i$ represents the unnormalized score for a
                            candidate token in the vocabulary. The probability of generating token $y_i$
                            , given the input X and previously generated
                            tokens y&lt;i, is computed using the softmax function:

                            \begin{align}
                            p\left(y_{i} \mid X, y_{&lt;i}\right) & = \frac{\exp \left(\mathbf{l}_{i,
                            y_{i}}\right)}{\sum_{y^{\prime}
                            \in
                            \mathcal{V}} \exp \left(\mathbf{l}_{i, y^{\prime}}\right)}
                            \end{align}

                            where $l_{i,{y_i}}$
                            is the logits value corresponding to token $y_i$ and
                            V is the vocabulary.
                        </div>
                        <div class="text" style="width: 100%;">
                            The predicted token $y_i$
                            is determined by selecting the token
                            with the highest probability:

                        </div>
                        <div>
                            $$
                            \begin{equation}
                            y_i=\arg \max _{y_i} p\left(y_i \mid X, y_{&lt;i}\right) \nonumber
                            \end{equation}
                            $$
                        </div>
                        <div class="title-little">
                            2. Soft Step Division
                        </div>
                        <div class="text" style="width: 100%;">
                            The entire output sequence Y can be partitioned into K
                            steps:
                            $$
                            \begin{equation}
                            \mathbf{Y}=\bigcup_{k=1}^K s_k, \nonumber
                            \end{equation}
                            $$
                        </div>
                        <div class="text">
                            where each step $s_k = \{ y_{r_{k-1}}, \dots, y_{r_k}\}$ is a contiguous subsequence of
                            tokens, and
                            rs are
                            division points. To divide the
                            answer into a step-by-step format, we follow the calculation
                            method of model confidence (Hills & Anadkat, 2024) using
                            the following equation:
                            $$
                            \begin{equation}
                            \text{C}_{y_i} = \exp{(\log p(y_i | X, y_{&lt;i}))},
                            \label{equ:confidence}
                            \end{equation}
                            $$
                            which is numerically equal to the predicted token probability,
                            where y&lt;i represents the preceding tokens. Tokens with
                            low confidence values are identified as delimited tokens,
                            representing the start of new step sequences. At the position
                            of each delimited token, we then perform N rollouts to
                            assess the quality of the current token sequence.

                        </div>
                        <div class="text">
                            We define a confidence threshold $\tau$ to select these delimited
                            tokens with low confidence. Specifically, for a dataset, we
                            first compute the confidence value for each token of the
                            answer part in the samples. The threshold $\tau$ is determined
                            as a specific percentile of the confidence distribution across
                            the dataset, ensuring an average of K âˆ’ 1 steps for each
                            sample divided by delimiter tokens. With the last step at the
                            end of the answer, each sample contains an average of K
                            steps.

                        </div>
                        <div class="title-little">
                            3. Reward Estimation
                        </div>
                        <div class="text">
                            For each step, we estimate the quality of individual steps in
                            an answer following the heuristic rollout methods proposed
                            by (Wang et al., 2024).
                        </div>
                        <div class="text">
                            During the rollout phase, we generate $N$ reasoning processes starting from step $s_i$,
                            denoted as
                            $\left\{s_i,
                            T_j\right\}^N_{j=1}$, where $T_j$ is the rollouted $j$-th solution with the previous
                            sequence $s_i$.
                            Then, we estimate the reward of this step based on the correctness of all decoded solutions.
                            We use
                            hard
                            estimation (HE) to estimate the reward for step $s_k$, which shows whether the current
                            inference
                            sequence
                            can
                            reach the correct answer. For example, in the Code domain, correct means the generated code
                            can pass
                            all the
                            test cases; in the Mathematics domain, it means the final answer matches the ground truth:


                            \begin{equation}
                            % y_{s_k}^{H E}= \mathbb I \left(\exists o_j \in O \mid o_j \text { is correct }\right)
                            y_{s_k}^{HE}=\left\{
                            \begin{aligned}
                            1 & & \exists t_j \in T, t_j \text { is correct } \\
                            0 & & \mathrm{Otherwise} \\
                            \end{aligned}
                            \right.
                            \label{eqa:HE}
                            \end{equation}
                        </div>
                        <div class="title-little">
                            4. PRM Guided Inference
                        </div>
                        <div class="text">
                            The PGI evaluation strategy leverages the well-trained PRM to enhance token selection during
                            decoding.
                            Specifically, when the model encounters a low-confidence position in the decoding sequence,
                            it
                            triggers the
                            PRM
                            to evaluate the top $M$ candidate tokens $y_t^*=\{y_1',y_2',\dots,y_M'\}$.

                            Among these candidates, the PRM selects the token it considers the best based on its learned
                            reward
                            estimation
                            mechanism:

                            \begin{equation}
                            y_t=\arg \max _{y_k' \in y_t^*} R\left(X, y_{&lt;t},y_k'\right),
                            \end{equation}
                            , where $y_t$ is the token selected as the optimal choice for decoding position $t$, and
                            $R(*)$
                            represents
                            the
                            PRM rewarding process.
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section hero ">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Experiment Results</h2>
                    <div class="content has-text-justified">
                        <div class="title-little">
                            1. Best of N Evaluation Results
                        </div>
                        <div class="text">
                            <strong>We show the Mathematics domain BoN evaluation results in Figure 4 and the Code
                                domain BoN evaluation results
                                in Figure 5.</strong>
                            In the Mathematics domain, we find that S<sup>2</sup>PRM-L performs best across Figure 4a,
                            4b and 4d. However, the
                            performance of S<sup>2</sup>PRM-M is generally the worst among all
                            the experiments, and we attribute this to the following factors: the <strong>base
                                model</strong>, the <strong>data
                                sources for construction</strong>,
                            and the <strong>costs and models for construction</strong>. 1) For the
                            base model, S<sup>2</sup>PRM-M uses Mistral, which is less capable
                            than Llama, resulting in poorer performance compared to
                            ER-PRM. 2) For the data sources, S<sup>2</sup>PRM only utilizes the
                            GSM8k and MATH training sets during training data construction, while both ER-PRM and
                            Math-Shepherd use the
                            MATH test set (without using MATH500), which results
                            in our performance being inferior to theirs on MATH500.
                            3) For the costs and models used in construction, the data
                            construction costs for S<sup>2</sup>PRM is approximately 60% of that
                            for the other two methods and only used a single construct
                            model, we will discuss our sample efficiency feature in
                            the next section. Additionally, Math-Shepherd performs
                            an extra epoch of training on the MetaMath model using
                            the GSM8k and MATH training sets before generating its
                            PRM training data, a step we did not follow. This could be
                            considered a data construction trick, contributing to their
                            better performance.
                        </div>
                        <div class="text">
                            In the two datasets of the Code domain, S<sup>2</sup>PRM-D demonstrates better judging
                            capabilities, and as the
                            number of
                            candidates increases, the robustness of S<sup>2</sup>PRM-D is superior to that of the ORM.
                        </div>
                        <div class="pic-box1">
                            <div class="picinbox">
                                <img src="static/images/figure-GSM8k_bon_candidates_llama_traindatamistral.png"
                                    style="width: 83%;">
                                <span>(a)</span>
                            </div>
                            <div class="picinbox">
                                <img src="static/images/figure-GSM8k_bon_candidates_mistral_traindatamistral.png"
                                    style="width: 95%;">
                                <span>(b)</span>
                            </div>
                            <div class="picinbox">
                                <img src="static/images/figure-MATH500_bon_candidates_llama_traindatamistral.png"
                                    style="width: 95%;">
                                <span>(c)</span>
                            </div>
                            <div class="picinbox">
                                <img src="static/images/figure-MATH500_bon_candidates_mistral_traindatamistral.png"
                                    style="width: 95%;">
                                <span>(d)</span>
                            </div>
                        </div>
                        <div class="text">
                            Figure 4. BoN results for the Mathematics domain, for S<sup>2</sup>PRM, we use the Mistral
                            generated training
                            dataset to align with
                            ER-PRM to train Mistral (S<sup>2</sup>PRM-M) and Llama (S<sup>2</sup>PRM-L) and test all the
                            PRMs on (a)
                            MetaMath-Llama generated
                            GSM8k BoN candidates; (b) MetaMath-Mistral generated GSM8k BoN candidates; (c)
                            MetaMath-Llama generated
                            MATH500 BoN candidates, and (d) MetaMath-Mistral generated MATH500 BoN candidates.

                            <div class="pic-box1">
                                <div class="picinbox">
                                    <img src="static/images/figure-LCT_bon_candidates_ds.png" style="width: 60%;">
                                    <span>(a)</span>
                                </div>
                                <div class="picinbox">
                                    <img src="static/images/figure-LCB_bon_candidates_ds.png" style="width: 60%;">
                                    <span>(b)</span>
                                </div>
                            </div>
                            <div class="text">
                                Figure 5. BoN results for the Code domain, we test S2PRMD and a Code-ORM (ORM-D) on (a)
                                DeepSeek-SFT generated
                                LeetCoTE BoN candidates; (b) DeepSeek-SFT generated LiveCodeBench BoN candidates.

                            </div>
                            <div class="title-little">
                                2. PRM Guided Inference Results

                            </div>
                            <div class="text">
                                We report PGI results in Table 1 and Table 2. In the Mathematics domain,
                                S<sup>2</sup>PRM has consistently shown
                                an ability
                                to enhance the reasoning capacity of the inference models,
                                while ER-PRM and Math-Shepherd do not have a positive
                                effect on the reasoning process on the GSM8k testset. The
                                results suggest that the judgment accuracy of S<sup>2</sup>PRM surpasses that of other
                                PRMs. Especially on
                                GSM8k, where
                                the performance of greedy search is already well, its performance further demonstrates
                                the accuracy of the
                                token-level
                                judgment. In the Code domain, S<sup>2</sup>PRM has also achieved
                                results surpassing those of greedy search by guiding the
                                reasoning model with accurate judgment.
                            </div>

                        </div>
                        <img src="static/images/table1.png" width="90%">
                        <div class="text">
                            Table 1: Mathematics domain PRM Guided Inference results. Acc@1 refers to the inference
                            modelâ€™s greedy search
                            performance. S<sup>2</sup>PRM-L represents Mathematics PRM based on Llama,
                            S<sup>2</sup>PRM-M represents Mathematics
                            PRM trained
                            based on Mistral.
                        </div>
                        <img src="static/images/table2.png" width="40%">
                        <div class="text">
                            Table 2: Code domain PRM Guided Inference results.
                            Pass@1 refers to the greedy search performance of the inference model (DeepSeek-SFT).
                        </div>
                    </div>
                </div>
            </div>
    </section>
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Findings</h2>
                    <div class="papercontent">
                        <div class="text">
                            <ul>
                                <li>The dataset construction cost of S2PRM demonstrates construct cost predictable and
                                    sample efficiency, as
                                    we only use almost 60% inference resource compared to previous open-sourced works.
                                </li>
                                <li>In the Mathematics domain, 3.85% tokens (tokens in mathematical expressions)
                                    contribute 21.03% decision
                                    tokens.</li>
                                <li>In the Code domain, most decision points occur in the Code Comment type (80%) but
                                    not in the Code type
                                    (20%), as 91% of lines of Code Comment are planning what to write in the following
                                    Code lines.</li>
                                <li>S2PRM exhibits in-domain and cross-domain generalization ability and scoring
                                    position generalization but
                                    faces challenges in length generalization.</li>
                                <li>Training models with data from multiple domains can enhance their performance and
                                    capabilities.</li>
                            </ul>
                            For more information, please refer to our paper.
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section hero ">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div style="width: 75%;">
                    <h2 class="title is-3">BibTex</h2>
                    <pre style="text-align:left;margin:0; padding:0;">
                    <code style="margin:0; padding:0; white-space: pre;">
@article{park2021nerfies,
         author = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz,Steven M. and Martin-Brualla, Ricardo},
         title = {Nerfies: Deformable Neural Radiance Fields},
         journal = {ICCV},
         year = {2021},
         }
                            </code>
                        </pre>
                </div>
            </div>
    </section>

    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Acknowledgements</h2>
                    <div class="papercontent">
                        <div class="text">
                            We sincerely thank Zilin Zhu for providing valuable suggestions on efficiency optimizations
                            of
                            our code and Di Yang for his advice during the completion
                            of the work.
                        </div>
                    </div>
                </div>
            </div>
        </div>







</body>

</html>